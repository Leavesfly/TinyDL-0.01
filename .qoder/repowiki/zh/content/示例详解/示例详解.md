# 示例详解

<cite>
**本文档中引用的文件**  
- [SpiralMlpExam.java](file://src/main/java/io/leavesfly/tinydl/example/classify/SpiralMlpExam.java)
- [SpiralDateSet.java](file://src/main/java/io/leavesfly/tinydl/mlearning/dataset/simple/SpiralDateSet.java)
- [Plot.java](file://src/main/java/io/leavesfly/tinydl/utils/Plot.java)
- [MnistMlpExam.java](file://src/main/java/io/leavesfly/tinydl/example/classify/MnistMlpExam.java)
- [MnistDataSet.java](file://src/main/java/io/leavesfly/tinydl/mlearning/dataset/simple/MnistDataSet.java)
- [MlpSinExam.java](file://src/main/java/io/leavesfly/tinydl/example/regress/MlpSinExam.java)
- [SinDataSet.java](file://src/main/java/io/leavesfly/tinydl/mlearning/dataset/simple/SinDataSet.java)
- [RnnCosExam.java](file://src/main/java/io/leavesfly/tinydl/example/regress/RnnCosExam.java)
- [CosDataSet.java](file://src/main/java/io/leavesfly/tinydl/mlearning/dataset/simple/CosDataSet.java)
- [SimpleRnnBlock.java](file://src/main/java/io/leavesfly/tinydl/nnet/block/SimpleRnnBlock.java)
- [Model.java](file://src/main/java/io/leavesfly/tinydl/mlearning/Model.java)
- [MlpBlock.java](file://src/main/java/io/leavesfly/tinydl/nnet/block/MlpBlock.java)
- [SoftmaxCrossEntropy.java](file://src/main/java/io/leavesfly/tinydl/mlearning/loss/SoftmaxCrossEntropy.java)
- [MeanSquaredLoss.java](file://src/main/java/io/leavesfly/tinydl/mlearning/loss/MeanSquaredLoss.java)
- [SGD.java](file://src/main/java/io/leavesfly/tinydl/mlearning/optimize/SGD.java)
- [MoEGPTExample.java](file://src/main/java/io/leavesfly/tinydl/example/nlp/MoEGPTExample.java)
- [MoEGPTModel.java](file://src/main/java/io/leavesfly/tinydl/modality/nlp/MoEGPTModel.java)
- [MultiArmedBanditExample.java](file://src/main/java/io/leavesfly/tinydl/example/rl/MultiArmedBanditExample.java)
- [CartPoleDQNExample.java](file://src/main/java/io/leavesfly/tinydl/example/rl/CartPoleDQNExample.java)
- [GridWorldREINFORCEExample.java](file://src/main/java/io/leavesfly/tinydl/example/rl/GridWorldREINFORCEExample.java)
- [Seq2SeqExample.java](file://src/main/java/io/leavesfly/tinydl/example/seq2seq/Seq2SeqExample.java)
</cite>

## 目录
1. [SpiralMlpExam.java 详解](#spiralmlpexamjava-详解)
2. [MnistMlpExam.java 详解](#mnistmlpexamjava-详解)
3. [MlpSinExam.java 详解](#mlpsinexamjava-详解)
4. [RnnCosExam.java 详解](#rnncosexamjava-详解)
5. [MoEGPTExample.java 详解](#moegptexamplejava-详解)
6. [MultiArmedBanditExample.java 详解](#multiarmedbanditexamplejava-详解)
7. [CartPoleDQNExample.java 详解](#cartpoledqnexamplejava-详解)
8. [GridWorldREINFORCEExample.java 详解](#gridworldreinforceexamplejava-详解)
9. [Seq2SeqExample.java 详解](#seq2seqexamplejava-详解)

## SpiralMlpExam.java 详解

该示例演示了如何使用多层感知机（MLP）对非线性可分的螺旋形数据进行分类，并通过可视化展示决策边界。

### 螺旋数据生成
`SpiralDateSet` 类生成三类螺旋分布的数据点。每类数据通过极坐标公式生成：
- 半径 `radius = 1.0 * rate`（`rate` 从 0 到 1）
- 角度 `theta = j * 4.0 + 4.0 * rate + 噪声`
- 坐标 `x = radius * sin(theta)`, `y = radius * cos(theta)`
其中 `j` 表示类别索引（0,1,2），`i` 表示每个类别中的样本索引。通过添加高斯噪声，使数据更具挑战性。

### MLP 模型构建
使用 `MlpBlock` 构建一个包含两个隐藏层的 MLP 模型：
- 输入层：2 维（x, y 坐标）
- 隐藏层：30 个神经元（两层）
- 输出层：3 维（对应三类）
激活函数默认为 ReLU。模型封装在 `Model` 类中，便于训练和推理。

### 训练与评估
- 优化器：SGD，学习率设为 1.0
- 损失函数：SoftmaxCrossEntropy（交叉熵损失）
- 批大小：10，训练轮数：300
训练过程中，每轮计算平均损失和准确率，并在控制台输出。

### 决策边界可视化
训练完成后，使用 `Plot.java` 工具生成一个 2000 点的网格，输入模型进行预测，得到每个点的类别。通过 `plot.scatter()` 分别绘制原始训练数据和预测结果的散点图，直观展示模型学习到的决策边界。

**Section sources**
- [SpiralMlpExam.java](file://src/main/java/io/leavesfly/tinydl/example/classify/SpiralMlpExam.java#L0-L130)
- [SpiralDateSet.java](file://src/main/java/io/leavesfly/tinydl/mlearning/dataset/simple/SpiralDateSet.java#L0-L79)
- [Plot.java](file://src/main/java/io/leavesfly/tinydl/utils/Plot.java)

## MnistMlpExam.java 详解

该示例展示了如何使用 MLP 模型对 MNIST 手写数字数据集进行分类。

### MNIST 数据集加载
`MnistDataSet` 类负责下载和加载 MNIST 数据集（如果本地不存在）。数据集包含：
- 训练集：60,000 张 28x28 的灰度图像
- 测试集：10,000 张 28x28 的灰度图像
图像数据被展平为 784 维向量，标签为 0-9 的整数。`doPrepare()` 方法读取 IDX 格式的压缩文件，并将像素值归一化到 [0,1] 区间。

### MLP 模型构建
构建一个三层 MLP 模型：
- 输入层：784 维（28*28 像素）
- 隐藏层1：100 个神经元
- 隐藏层2：100 个神经元
- 输出层：10 维（对应 10 个数字）
激活函数使用 Sigmoid。模型同样封装在 `Model` 类中。

### 训练与评估
- 优化器：SGD，学习率设为 0.1
- 损失函数：SoftmaxCrossEntropy
- 批大小：100，训练轮数：50
使用 `Trainer` 类进行训练，`AccuracyEval` 作为评估器。训练完成后，`trainer.evaluate()` 在测试集上计算分类准确率。预期准确率约为 91%。

**Section sources**
- [MnistMlpExam.java](file://src/main/java/io/leavesfly/tinydl/example/classify/MnistMlpExam.java#L0-L69)
- [MnistDataSet.java](file://src/main/java/io/leavesfly/tinydl/mlearning/dataset/simple/MnistDataSet.java#L0-L181)
- [MlpBlock.java](file://src/main/java/io/leavesfly/tinydl/nnet/block/MlpBlock.java)
- [SoftmaxCrossEntropy.java](file://src/main/java/io/leavesfly/tinydl/mlearning/loss/SoftmaxCrossEntropy.java)
- [SGD.java](file://src/main/java/leavesfly/tinydl/mlearning/optimize/SGD.java)

## MlpSinExam.java 详解

该示例演示了如何使用 MLP 模型对带有噪声的正弦波数据进行回归拟合。

### 正弦波数据生成
`SinDataSet` 类生成 100 个带有噪声的正弦波数据点：
- 输入 `x`：在 [0,1) 区间内随机采样
- 输出 `y`：`sin(2πx) + noise`，其中 `noise` 为随机噪声
数据通过 `prepare()` 方法准备，并划分为批次。

### MLP 模型构建
构建一个简单的 MLP 模型用于回归：
- 输入层：1 维（x 值）
- 隐藏层：10 个神经元
- 输出层：1 维（y 值）
激活函数使用 Sigmoid。模型结构由 `MlpBlock` 定义。

### 回归训练
- 优化器：SGD，学习率设为 0.2
- 损失函数：MeanSquaredLoss（均方误差损失）
- 训练轮数：10,000
训练过程手动循环，每次前向传播计算预测值，计算损失，反向传播更新梯度，最后调用 `optimizer.update()` 更新参数。损失值随训练轮数下降。

### 预测结果可视化
训练完成后，使用 `Plot.java` 绘制原始数据点（散点图）和模型预测的曲线（折线图）。预期结果是预测曲线能够较好地拟合正弦波的趋势，但由于噪声存在，不会完全重合。

**Section sources**
- [MlpSinExam.java](file://src/main/java/io/leavesfly/tinydl/example/regress/MlpSinExam.java#L0-L69)
- [SinDataSet.java](file://src/main/java/io/leavesfly/tinydl/mlearning/dataset/simple/SinDataSet.java#L0-L34)
- [MeanSquaredLoss.java](file://src/main/java/io/leavesfly/tinydl/mlearning/loss/MeanSquaredLoss.java)
- [Plot.java](file://src/main/java/io/leavesfly/tinydl/utils/Plot.java)

## RnnCosExam.java 详解

该示例展示了如何使用简单 RNN（SimpleRNN）对余弦序列进行时间序列预测。

### 余弦序列数据生成
`CosDataSet` 类生成用于训练和测试的序列数据：
- 训练数据：`sin(2πt)` 序列，用于预测下一个值
- 测试数据：`cos(2πt)` 序列，用于评估模型泛化能力
数据被构造成输入-输出对：输入是当前值 `x_t`，输出是下一个值 `x_{t+1}`。`bpttLength` 参数控制反向传播通过时间的长度。

### RNN 模型构建
使用 `SimpleRnnBlock` 构建一个简单的 RNN 模型：
- 输入大小：1
- 隐藏层大小：20
- 输出大小：1
RNN 模型具有内部状态，能够捕捉序列中的时间依赖关系。

### 时间序列预测训练
- 优化器：SGD，学习率设为 0.01
- 损失函数：MeanSquaredLoss
- 训练轮数：100
训练过程的关键点：
1.  **状态重置**：每轮训练开始前调用 `model.resetState()` 清除隐藏状态，防止状态在轮次间传递。
2.  **序列处理**：对于每个批次，循环处理序列中的每个时间步，将当前输入送入模型，得到预测，并与真实下一个值计算损失。
3.  **损失累积**：将一个批次内所有时间步的损失累加，然后进行反向传播和参数更新。
4.  **计算图切断**：在批次处理结束后调用 `loss.unChainBackward()` 切断计算图，防止梯度回传到上一个批次，实现截断的 BPTT (Truncated BPTT)。

### Teacher Forcing 技术
本示例中，模型的输入是真实的历史数据（`xArray[j]`），而不是模型自己上一步的预测。这种使用真实值作为下一步输入的方法称为 **Teacher Forcing**。它有助于模型在训练初期更稳定地学习，避免了错误累积的问题。

**Section sources**
- [RnnCosExam.java](file://src/main/java/io/leavesfly/tinydl/example/regress/RnnCosExam.java#L0-L91)
- [CosDataSet.java](file://src/main/java/io/leavesfly/tinydl/mlearning/dataset/simple/CosDataSet.java#L0-L48)
- [SimpleRnnBlock.java](file://src/main/java/io/leavesfly/tinydl/nnet/block/SimpleRnnBlock.java)
- [Model.java](file://src/main/java/io/leavesfly/tinydl/mlearning/Model.java#L0-L100)

## MoEGPTExample.java 详解

该示例详细介绍了如何使用混合专家模型（MoE）架构的GPT模型进行文本生成任务。

### MoE-GPT模型创建
`MoEGPTModel` 类实现了基于Transformer的MoE架构。其核心组件包括：
- **Token嵌入层** (`GPT2TokenEmbedding`)：将输入token转换为向量表示。
- **MoE Transformer块** (`MoETransformerBlock`)：包含多个专家网络和门控机制，仅激活Top-K个专家。
- **最终层归一化** (`LayerNorm`) 和 **输出头** (`GPT2OutputHead`)：完成最终的特征变换和词汇表投影。

模型提供了多种工厂方法以创建不同规模的实例：
- `createSmallModel()`：小规模模型，适合实验和快速原型。
- `createMediumModel()`：中等规模模型，平衡性能与效率。
- `createTinyModel()`：微型模型，用于调试和概念验证。

### 训练数据准备
示例使用预定义的中文训练文本数组 `TRAINING_TEXTS`。通过 `SimpleTokenizer` 进行简化分词，将文本转换为token ID序列。`prepareTrainingData()` 方法负责构建训练所需的序列数据。

### 模型训练流程
训练采用简化的循环方式，不依赖 `Trainer` 类：
1.  **批次准备**：`prepareBatch()` 方法将训练数据组织成输入-目标对，输入为序列的前n-1个token，目标为后n-1个token。
2.  **前向传播**：调用 `model.forward()` 进行预测。
3.  **损失计算**：除了主损失外，还计算并累加 `loadBalancingLoss` 以鼓励专家间的负载均衡。
4.  **参数更新**：通过 `optimizer.update()` 更新模型参数。

### 专家使用分析
`analyzeMoEUsage()` 方法深入分析了MoE层的专家使用情况：
- **使用率统计**：`printSimpleExpertUsage()` 显示各层每个专家的使用率。
- **负载均衡分析**：`analyzeLoadBalancing()` 计算负载均衡分数，分数越高表示专家使用越均匀。

### 文本生成测试
`testTextGeneration()` 方法演示了模型的推理能力。给定提示词（如“人工智能”），模型通过贪心解码（`predictNextToken()`）逐个生成后续token，形成连贯的文本。

### 性能分析
`performanceAnalysis()` 方法对比了MoE模型与传统密集模型的效率：
- **总参数量** (`getParameterCount()`)：包含所有专家的参数。
- **激活参数量** (`getActiveParameterCount()`)：仅包含实际参与计算的参数（Top-K专家）。
- **参数效率**：激活参数量占总参数量的百分比，体现了MoE模型的稀疏性优势。

**Section sources**
- [MoEGPTExample.java](file://src/main/java/io/leavesfly/tinydl/example/nlp/MoEGPTExample.java#L0-L480)
- [MoEGPTModel.java](file://src/main/java/io/leavesfly/tinydl/modality/nlp/MoEGPTModel.java#L0-L512)
- [SimpleTokenizer.java](file://src/main/java/io/leavesfly/tinydl/modality/nlp/SimpleTokenizer.java#L0-L365)

## MultiArmedBanditExample.java 详解

该示例系统地比较了多种多臂老虎机算法在解决探索-利用困境上的性能。

### 实验设置
- **环境**：`MultiArmedBanditEnvironment` 模拟了一个有5个臂的老虎机，每个臂有固定的期望奖励（`TRUE_REWARDS`）。
- **智能体**：实现了四种不同的策略：
    - **ε-贪心** (`EpsilonGreedyBanditAgent`)：以概率ε进行探索，否则选择当前最优臂。
    - **UCB** (`UCBBanditAgent`)：使用置信区间上界公式，平衡探索与利用。
    - **汤普森采样** (`ThompsonSamplingBanditAgent`)：基于贝叶斯推断，从后验分布中采样来选择动作。
- **评估指标**：累积奖励、累积悔恨、最优动作选择率。

### 多次运行实验
`runComparisonExperiment()` 方法执行10次独立运行，以减少随机性影响。每次运行中，所有智能体在同一环境下进行1000步交互。结果显示：
- **ε-贪心**：性能受ε值影响大，衰减的ε通常优于固定ε。
- **UCB**：表现稳健，能有效平衡探索与利用。
- **汤普森采样**：在某些场景下表现最佳，尤其当奖励分布符合其先验假设时。

### 单次详细实验
`runDetailedSingleExperiment()` 提供了单次运行的详细日志，展示智能体在每一步的选择、获得的奖励和瞬时悔恨，有助于理解算法的动态行为。

**Section sources**
- [MultiArmedBanditExample.java](file://src/main/java/io/leavesfly/tinydl/example/rl/MultiArmedBanditExample.java#L0-L292)
- [MultiArmedBanditEnvironment.java](file://src/main/java/io/leavesfly/tinydl/modality/rl/environment/MultiArmedBanditEnvironment.java#L0-L266)
- [EpsilonGreedyBanditAgent.java](file://src/main/java/io/leavesfly/tinydl/modality/rl/agent/EpsilonGreedyBanditAgent.java#L0-L182)
- [UCBBanditAgent.java](file://src/main/java/io/leavesfly/tinydl/modality/rl/agent/UCBBanditAgent.java#L0-L241)
- [ThompsonSamplingBanditAgent.java](file://src/main/java/io/leavesfly/tinydl/modality/rl/agent/ThompsonSamplingBanditAgent.java#L0-L338)

## CartPoleDQNExample.java 详解

该示例演示了如何使用深度Q网络（DQN）算法解决CartPole平衡问题。

### 环境与智能体
- **环境**：`CartPoleEnvironment` 模拟了经典的倒立摆系统，状态空间为4维（小车位置、速度、杆子角度、角速度），动作空间为2维（向左或向右施加力）。
- **智能体**：`DQNAgent` 实现了DQN算法，包含以下关键组件：
    - **Q网络** (`model`)：估计状态-动作价值。
    - **目标网络** (`targetModel`)：提供稳定的Q值目标。
    - **经验回放缓冲区** (`replayBuffer`)：存储历史经验以打破数据相关性。
    - **ε-贪婪策略** (`policy`)：控制探索与利用。

### DQN训练流程
`trainAgent()` 方法实现了标准的DQN训练循环：
1.  **交互**：智能体与环境交互，收集经验并存入缓冲区。
2.  **采样**：当缓冲区足够大时，从中采样一个批次的经验。
3.  **学习**：计算目标Q值（`computeTargetQValues()`）和当前Q值（`computeCurrentQValues()`），通过最小化均方误差损失来更新Q网络。
4.  **目标网络更新**：定期将Q网络的权重复制到目标网络。
5.  **探索率衰减**：随着训练进行，逐步降低ε值，减少探索。

### 评估与演示
`evaluateAgent()` 在训练结束后评估智能体性能，计算平均奖励和成功率。`demonstrateEpisode()` 可视化单个回合的执行过程，帮助理解智能体的决策。

**Section sources**
- [CartPoleDQNExample.java](file://src/main/java/io/leavesfly/tinydl/example/rl/CartPoleDQNExample.java#L0-L241)
- [DQNAgent.java](file://src/main/java/io/leavesfly/tinydl/modality/rl/agent/DQNAgent.java#L0-L396)
- [CartPoleEnvironment.java](file://src/main/java/io/leavesfly/tinydl/modality/rl/environment/CartPoleEnvironment.java#L0-L257)

## GridWorldREINFORCEExample.java 详解

该示例展示了如何使用REINFORCE算法（一种策略梯度方法）解决GridWorld导航问题。

### 环境与智能体
- **环境**：`GridWorldEnvironment` 创建一个二维网格世界，智能体需要从起点移动到终点，避开障碍物。状态为智能体的(x,y)坐标，动作为上下左右。
- **智能体**：`REINFORCEAgent` 实现了REINFORCE算法，其核心是直接优化策略网络。

### REINFORCE训练流程
`trainAgent()` 方法遵循回合制学习：
1.  **回合执行**：智能体在一个完整回合中与环境交互，记录所有状态、动作、奖励和对数概率。
2.  **回报计算**：从后往前计算每个时间步的折扣回报。
3.  **策略更新**：使用策略梯度定理，通过最大化期望回报来更新策略网络。梯度方向为 `-log(π(a|s)) * A(s,a)`，其中A是优势函数。
4.  **基线应用**：`useBaseline` 参数决定是否引入价值函数作为基线，以减少梯度方差，加速收敛。

### 基线的作用
示例通过对比`useBaseline=true`和`useBaseline=false`的版本，清晰地展示了基线的重要性。使用基线可以显著降低训练过程中的方差，使学习更加稳定和高效。

### 评估与策略演示
`evaluateAgent()` 和 `demonstrateLearnedPolicy()` 方法用于评估和可视化智能体学到的策略，确认其能否成功导航至目标。

**Section sources**
- [GridWorldREINFORCEExample.java](file://src/main/java/io/leavesfly/tinydl/example/rl/GridWorldREINFORCEExample.java#L0-L292)
- [REINFORCEAgent.java](file://src/main/java/io/leavesfly/tinydl/modality/rl/agent/REINFORCEAgent.java#L0-L488)
- [GridWorldEnvironment.java](file://src/main/java/io/leavesfly/tinydl/modality/rl/environment/GridWorldEnvironment.java#L0-L391)

## Seq2SeqExample.java 详解

该示例介绍了如何构建和使用序列到序列（Seq2Seq）模型，适用于机器翻译、文本摘要等任务。

### 模型构建方式
示例展示了两种构建Seq2Seq模型的方式：
1.  **组合式** (`EncoderDecoder`)：使用 `EncoderDecoder` 类将编码器和解码器组合成一个完整的模型。这是最简洁的用法。
2.  **分离式**：分别创建 `Seq2SeqEncoder` 和 `Seq2SeqDecoder`，允许对编码和解码过程进行更精细的控制。

### 编码器与解码器
- **编码器** (`Seq2SeqEncoder`)：接收源语言序列，将其编码为一个上下文向量（或一系列隐藏状态）。
- **解码器** (`Seq2SeqDecoder`)：以编码器的输出为初始状态，自回归地生成目标语言序列。

### 前向传播流程
1.  **编码阶段**：源序列输入编码器，得到编码后的表示。
2.  **状态初始化**：将编码器的最终状态传递给解码器，作为其初始隐藏状态。
3.  **解码阶段**：目标序列（通常以起始符开头）输入解码器，生成最终的输出序列。

### 应用场景
此模型广泛应用于：
- **机器翻译**：将一种语言的句子翻译成另一种语言。
- **文本摘要**：将长篇文章浓缩为简短摘要。
- **对话系统**：根据用户输入生成回复。

**Section sources**
- [Seq2SeqExample.java](file://src/main/java/io/leavesfly/tinydl/example/seq2seq/Seq2SeqExample.java#L0-L192)
- [Seq2SeqEncoder.java](file://src/main/java/io/leavesfly/tinydl/nnet/block/seq2seq/Seq2SeqEncoder.java)
- [Seq2SeqDecoder.java](file://src/main/java/io/leavesfly/tinydl/nnet/block/seq2seq/Seq2SeqDecoder.java)
- [EncoderDecoder.java](file://src/main/java/io/leavesfly/tinydl/nnet/block/seq2seq/EncoderDecoder.java)