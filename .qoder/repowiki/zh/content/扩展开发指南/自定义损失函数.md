# 自定义损失函数

<cite>
**本文档引用的文件**  
- [Loss.java](file://src/main/java/io/leavesfly/tinydl/mlearning/loss/Loss.java)
- [SoftmaxCrossEntropy.java](file://src/main/java/io/leavesfly/tinydl/mlearning/loss/SoftmaxCrossEntropy.java)
- [MeanSE.java](file://src/main/java/io/leavesfly/tinydl/func/loss/MeanSE.java)
- [SoftmaxCE.java](file://src/main/java/io/leavesfly/tinydl/func/loss/SoftmaxCE.java)
- [Variable.java](file://src/main/java/io/leavesfly/tinydl/func/Variable.java)
- [Function.java](file://src/main/java/io/leavesfly/tinydl/func/Function.java)
</cite>

## 目录
1. [引言](#引言)
2. [继承Loss基类的基本结构](#继承loss基类的基本结构)
3. [forward方法：损失值的标量输出与计算图构建](#forward方法损失值的标量输出与计算图构建)
4. [backward方法：梯度计算与自动微分支持](#backward方法梯度计算与自动微分支持)
5. [Huber Loss实现模板](#huber-loss实现模板)
6. [SoftmaxCrossEntropy的数值稳定性分析](#softmaxcrossentropy的数值稳定性分析)
7. [常见问题与调试建议](#常见问题与调试建议)
8. [总结](#总结)

## 引言
在TinyDL框架中，开发者可以通过继承`Loss`基类来实现自定义的损失函数。损失函数是模型训练的核心组件，其正确实现直接影响模型的收敛性与性能。本文档详细指导如何实现新的损失函数，重点说明`forward`方法中损失值的标量输出要求、计算图的构建机制、`backward`方法中梯度的数学推导与实现，以及数值稳定性处理等关键问题。

## 继承Loss基类的基本结构
所有损失函数均需继承自`Loss`抽象类，该类定义了统一的接口：

```java
public abstract class Loss {
    public abstract Variable loss(Variable y, Variable predict);
}
```

开发者需实现`loss`方法，接收真实标签`y`和模型预测值`predict`，返回一个`Variable`类型的损失值。该方法通常调用底层`Function`子类完成具体计算。

**Section sources**
- [Loss.java](file://src/main/java/io/leavesfly/tinydl/mlearning/loss/Loss.java#L0-L9)

## forward方法：损失值的标量输出与计算图构建
`forward`方法负责执行损失函数的前向传播，其输出必须为**标量（scalar）**，即形状为`[1]`的`NdArray`。这是反向传播的起点，因为梯度从损失值开始回传。

以均方误差（MSE）为例，其`forward`实现如下：

```java
public NdArray forward(NdArray... inputs) {
    NdArray predict = inputs[0];
    NdArray labelY = inputs[1];
    int size = predict.getShape().getRow();
    return predict.sub(labelY).square().sum().divNum(size);
}
```

该方法通过链式调用基本运算（`sub`, `square`, `sum`, `divNum`）构建计算图。每个运算都对应一个`Function`节点，`Variable`通过`setCreator`记录生成它的函数，从而形成完整的计算图，支持后续的自动微分。

**Section sources**
- [MeanSE.java](file://src/main/java/io/leavesfly/tinydl/func/loss/MeanSE.java#L10-L18)
- [Function.java](file://src/main/java/io/leavesfly/tinydl/func/Function.java#L45-L55)

## backward方法：梯度计算与自动微分支持
`backward`方法接收上游传来的梯度`yGrad`（通常为1.0），并根据损失函数对输入变量的偏导数计算梯度。

以MSE为例，损失函数为：
$$
L = \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2
$$
对预测值$\hat{y}_i$的梯度为：
$$
\frac{\partial L}{\partial \hat{y}_i} = \frac{2}{N} (\hat{y}_i - y_i) \cdot \text{gy}
$$
其中`gy`是上游梯度。

其Java实现如下：

```java
public List<NdArray> backward(NdArray yGrad) {
    NdArray predict = inputs[0].getValue();
    NdArray labelY = inputs[1].getValue();
    NdArray diff = predict.sub(labelY);
    int len = diff.getShape().getRow();
    NdArray gx0 = yGrad.broadcastTo(diff.getShape()).mul(diff).mulNum(2).divNum(len);
    return Arrays.asList(gx0, gx0.neg());
}
```

`backward`方法必须返回一个`List<NdArray>`，其长度与`forward`的输入数量一致，分别对应每个输入变量的梯度。

**Section sources**
- [MeanSE.java](file://src/main/java/io/leavesfly/tinydl/func/loss/MeanSE.java#L20-L35)
- [Function.java](file://src/main/java/io/leavesfly/tinydl/func/Function.java#L75-L85)

## Huber Loss实现模板
Huber Loss结合了MSE和MAE的优点，在误差较小时使用平方损失，在误差较大时使用线性损失，具有更强的鲁棒性。

```java
public class HuberLoss extends Function {
    private float delta;

    public HuberLoss(float delta) {
        this.delta = delta;
    }

    @Override
    public NdArray forward(NdArray... inputs) {
        NdArray predict = inputs[0];
        NdArray labelY = inputs[1];
        NdArray diff = predict.sub(labelY).abs();

        NdArray loss;
        if (diff.getNumber().floatValue() <= delta) {
            // 小误差：0.5 * diff^2
            loss = diff.square().mulNum(0.5f);
        } else {
            // 大误差：delta * |diff| - 0.5 * delta^2
            loss = diff.mulNum(delta).subNum(0.5f * delta * delta);
        }
        return loss.sum().divNum((float) predict.getShape().getRow());
    }

    @Override
    public List<NdArray> backward(NdArray yGrad) {
        NdArray predict = inputs[0].getValue();
        NdArray labelY = inputs[1].getValue();
        NdArray diff = predict.sub(labelY);
        int len = predict.getShape().getRow();
        float scale = yGrad.getNumber().floatValue() / len;

        NdArray grad;
        if (diff.getNumber().floatValue() < -delta) {
            grad = diff.like(-delta * scale);
        } else if (diff.getNumber().floatValue() > delta) {
            grad = diff.like(delta * scale);
        } else {
            grad = diff.mulNum(scale);
        }
        return Arrays.asList(grad, grad.neg());
    }

    @Override
    public int requireInputNum() {
        return 2;
    }
}
```

**Section sources**
- [MeanSE.java](file://src/main/java/io/leavesfly/tinydl/func/loss/MeanSE.java#L10-L39)
- [SoftmaxCE.java](file://src/main/java/io/leavesfly/tinydl/func/loss/SoftmaxCE.java#L10-L60)

## SoftmaxCrossEntropy的数值稳定性分析
`SoftmaxCrossEntropy`的实现中，`SoftmaxCE`类通过**log-sum-exp技巧**保证数值稳定性。直接计算`log(sum(exp(x)))`可能导致上溢或下溢。

其`forward`方法实现如下：

```java
NdArray max = predict.max(1);
NdArray max2PredictShape = max.broadcastTo(predict.getShape());
max = max.add(predict.sub(max2PredictShape).exp().sumTo(new Shape(row, 1)).log());
```

该技巧通过减去最大值`max`，将输入缩放到`[0, exp(x_i - max)]`范围内，避免指数运算溢出。最终损失值为：
$$
L = -\frac{1}{N} \sum_{i=1}^{N} (x_{i,y_i} - \max(x_i) - \log(\sum_j \exp(x_{i,j} - \max(x_i))))
$$

此实现确保了在大数值输入下的稳定性。

**Section sources**
- [SoftmaxCE.java](file://src/main/java/io/leavesfly/tinydl/func/loss/SoftmaxCE.java#L10-L35)
- [SoftmaxCrossEntropy.java](file://src/main/java/io/leavesfly/tinydl/mlearning/loss/SoftmaxCrossEntropy.java#L0-L10)

## 常见问题与调试建议
### 梯度维度不匹配
**问题**：`backward`返回的梯度`NdArray`形状与输入变量不一致。  
**原因**：未正确处理广播（broadcast）或聚合（sum）操作。  
**解决**：使用`broadcastTo`确保梯度形状匹配，或通过`sumTo`还原维度。

### 梯度符号错误
**问题**：模型参数向错误方向更新。  
**原因**：导数计算符号错误，如`predict - label`误写为`label - predict`。  
**解决**：仔细核对数学公式，使用单元测试验证梯度。

### 数值不稳定
**问题**：损失值为`NaN`或`Inf`。  
**原因**：未处理`log(0)`或`exp`溢出。  
**解决**：采用`log-sum-exp`等技巧，或对输入进行裁剪（clip）。

### 调试建议
1. 使用`Variable.getGrad()`打印中间梯度。
2. 实现简单的数值梯度检查（numerical gradient check）。
3. 利用`Config.train = false`关闭计算图构建以隔离问题。

**Section sources**
- [SoftmaxCE.java](file://src/main/java/io/leavesfly/tinydl/func/loss/SoftmaxCE.java#L40-L60)
- [Variable.java](file://src/main/java/io/leavesfly/tinydl/func/Variable.java#L100-L150)

## 总结
继承`Loss`基类实现自定义损失函数需重点关注：
1. `forward`方法输出必须为标量，并正确构建计算图。
2. `backward`方法需根据数学导数精确计算梯度，返回与输入对应的梯度列表。
3. 实现如Huber Loss时，需根据误差大小切换梯度逻辑。
4. 对于`SoftmaxCrossEntropy`等函数，必须使用`log-sum-exp`等技巧保证数值稳定性。
5. 注意梯度维度、符号及数值范围，通过调试工具验证实现正确性。

遵循上述指导，开发者可安全、高效地扩展TinyDL的损失函数库。