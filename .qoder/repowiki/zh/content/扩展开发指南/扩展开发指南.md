# 扩展开发指南

<cite>
**本文档中引用的文件**  
- [LayerAble.java](file://src/main/java/io/leavesfly/tinydl/nnet/LayerAble.java)
- [LinearLayer.java](file://src/main/java/io/leavesfly/tinydl/nnet/layer/dnn/LinearLayer.java)
- [Loss.java](file://src/main/java/io/leavesfly/tinydl/mlearning/loss/Loss.java)
- [MeanSquaredLoss.java](file://src/main/java/io/leavesfly/tinydl/mlearning/loss/MeanSquaredLoss.java)
- [Optimizer.java](file://src/main/java/io/leavesfly/tinydl/mlearning/optimize/Optimizer.java)
- [Adam.java](file://src/main/java/io/leavesfly/tinydl/mlearning/optimize/Adam.java)
- [DataSet.java](file://src/main/java/io/leavesfly/tinydl/mlearning/dataset/DataSet.java)
- [ArrayDataset.java](file://src/main/java/io/leavesfly/tinydl/mlearning/dataset/ArrayDataset.java)
</cite>

## 目录
1. [自定义神经网络层](#自定义神经网络层)
2. [实现新的损失函数](#实现新的损失函数)
3. [实现新的优化器](#实现新的优化器)
4. [加载自定义数据集](#加载自定义数据集)

## 自定义神经网络层

在本框架中，所有神经网络层均需继承 `LayerAble` 抽象类。开发者通过实现 `layerForward` 方法定义前向传播逻辑，并通过 `init` 方法初始化可学习参数（Parameter）。每个层需管理自身的参数字典 `params`，并通过 `addParam` 方法注册参数。`clearGrads` 方法用于在反向传播前清空梯度。

例如，`LinearLayer` 实现了一个全连接层，其权重 `w` 和偏置 `b` 被注册为参数，并在 `layerForward` 中调用线性变换操作。开发者在实现自定义层时，应确保前向传播的输入输出维度正确，并在反向传播时正确传递梯度。

**关键点：**
- 必须重写 `layerForward` 以定义前向逻辑
- 参数需通过 `addParam` 注册以便优化器更新
- `init` 方法可用于参数初始化策略
- `clearGrads` 需清空所有参数梯度

**Section sources**
- [LayerAble.java](file://src/main/java/io/leavesfly/tinydl/nnet/LayerAble.java#L15-L83)
- [LinearLayer.java](file://src/main/java/io/leavesfly/tinydl/nnet/layer/dnn/LinearLayer.java#L15-L53)

## 实现新的损失函数

要实现新的损失函数，需继承 `Loss` 抽象基类并重写 `loss` 方法。该方法接收真实标签 `y` 和模型预测值 `predict`，返回一个标量 `Variable` 表示损失值。损失函数的实现需确保其可微，以便自动求导系统能正确计算梯度。

例如，`MeanSquaredLoss` 类通过调用 `predict.meanSquaredError(y)` 实现均方误差损失。开发者在实现自定义损失函数时，应验证其数学表达式的正确性，并确保在极端输入下（如零值或极大值）数值稳定性。

**关键点：**
- `loss` 方法必须返回 `Variable` 类型
- 损失值应为标量（shape 为 []）
- 需正确实现梯度计算逻辑（通过函数链自动完成）
- 建议在测试中验证梯度近似值

**Section sources**
- [Loss.java](file://src/main/java/io/leavesfly/tinydl/mlearning/loss/Loss.java#L5-L10)
- [MeanSquaredLoss.java](file://src/main/java/io/leavesfly/tinydl/mlearning/loss/MeanSquaredLoss.java#L8-L14)

## 实现新的优化器

新的优化算法需继承 `Optimizer` 抽象类，并实现 `updateOne` 方法。`update` 方法会遍历模型所有参数并调用 `updateOne` 进行更新。优化器可维护内部状态（如动量、历史梯度等），并在更新时应用特定策略。

例如，`Adam` 优化器维护了 `ms` 和 `vs` 字典以存储一阶和二阶动量，并在 `updateOne` 中实现其更新公式。开发者在实现如 RMSprop 或 Adagrad 时，需正确管理每个参数的累积状态，并确保学习率调度逻辑正确。

**关键点：**
- `updateOne` 是核心更新逻辑入口
- 可通过 `parameter.getGrad()` 获取梯度
- 参数值通过 `parameter.setValue()` 更新
- 建议使用参数的哈希码作为状态键

**Section sources**
- [Optimizer.java](file://src/main/java/io/leavesfly/tinydl/mlearning/optimize/Optimizer.java#L10-L28)
- [Adam.java](file://src/main/java/io/leavesfly/tinydl/mlearning/optimize/Adam.java#L15-L70)

## 加载自定义数据集

要加载自定义数据集，需继承 `DataSet` 抽象类或更具体的 `ArrayDataset`。`DataSet` 定义了 `getBatches`、`shuffle`、`splitDataset` 等核心方法。对于能全量加载到内存的数据，推荐继承 `ArrayDataset` 并实现 `build` 方法以支持数据集拆分。

`ArrayDataset` 将输入输出数据存储为 `NdArray[]` 数组，并在 `getBatches` 中按批次组织数据。开发者在实现自定义数据集时，需确保 `prepare` 方法完成数据预处理，`shuffle` 方法正确打乱样本顺序，并在 `build` 中构造同类型的数据集实例。

**关键点：**
- `getBatches` 返回批处理后的数据列表
- `shuffle` 应保持输入输出样本的对应关系
- `splitDataset` 按比例划分训练/测试/验证集
- `build` 方法用于创建子集实例

**Section sources**
- [DataSet.java](file://src/main/java/io/leavesfly/tinydl/mlearning/dataset/DataSet.java#L10-L62)
- [ArrayDataset.java](file://src/main/java/io/leavesfly/tinydl/mlearning/dataset/ArrayDataset.java#L15-L116)